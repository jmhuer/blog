# Datasets

For each dataset below, click the 'source' link to see the dataset license and details from the creator, the 'cite' link for the paper for citations, and the 'download' link to access to dataset from [AWS Open Datasets](https://registry.opendata.aws/).

## Image classification

Source | Citation | Download | Description
--- | --- | --- | ---
[MNIST](http://yann.lecun.com/exdb/mnist/) | [LeCun et al., 1998a](http://yann.lecun.com/exdb/publis/index.html#lecun-98) | [download](https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz) | Classic dataset of small (28x28) handwritten grayscale digits, developed in the 1990s for testing the most sophisticated models of the day; today, often used as a basic "hello world" for introducing deep learning. This fast.ai datasets version uses a standard PNG format instead of the special binary format of the original, so you can use the regular data pipelines in most libraries; if you want to use just a single input channel like the original, simply pick a single slice from the channels axis.
[CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) | [Krizhevsky, 2009](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf) | [download](https://s3.amazonaws.com/fast-ai-imageclas/cifar10.tgz) | 60000 32x32 colour images in 10 classes, with 6000 images per class (50000 training images and 10000 test images). Very widely used today for testing performance of new algorithms. This fast.ai datasets version uses a standard PNG format instead of the platform-specific binary formats of the original, so you can use the regular data pipelines in most libraries.
[CIFAR100](https://www.cs.toronto.edu/~kriz/cifar.html) | [Krizhevsky, 2009](https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf) | [download](https://s3.amazonaws.com/fast-ai-imageclas/cifar100.tgz) | This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a "fine" label (the class to which it belongs) and a "coarse" label (the superclass to which it belongs).
[Caltech-UCSD Birds-200-2011](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) | [Lin et al. 2015](http://vis-www.cs.umass.edu/bcnn/) | [download](https://s3.amazonaws.com/fast-ai-imageclas/CUB_200_2011.tgz) | An image dataset with photos of 200 bird species (mostly North American); it can also be used for localization. Number of categories: 200; Number of images: 11,788; Annotations per image: 15 Part Locations, 312 Binary Attributes, 1 Bounding Box
[Caltech 101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/) | [L. Fei-Fei et al., 2004](http://www.vision.caltech.edu/feifeili/Fei-Fei_GMBV04.pdf) | [download](https://s3.amazonaws.com/fast-ai-imageclas/caltech_101.tar.gz) | Pictures of objects belonging to 101 categories. About 40 to 800 images per category. Most categories have about 50 images. The size of each image is roughly 300 x 200 pixels. Can also be used for localization.
[Oxford-IIIT Pet](http://www.robots.ox.ac.uk/~vgg/data/pets/) | [O. M. Parkhi et al., 2012](http://www.robots.ox.ac.uk/~vgg/publications/2012/parkhi12a/parkhi12a.pdf) | [download](https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz) | A 37 category pet dataset with roughly 200 images for each class. The images have a large variations in scale, pose and lighting. Can also be used for localization.
[Oxford 102 Flowers](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/) | [Nilsback, M-E. and Zisserman, A., 2008](http://www.robots.ox.ac.uk/~vgg/publications/papers/nilsback08.pdf) | [download](https://s3.amazonaws.com/fast-ai-imageclas/oxford-102-flowers.tgz) | A 102 category dataset consisting of 102 flower categories, commonly occuring in the United Kingdom. Each class consists of 40 to 258 images. The images have large scale, pose and light variations.
[Food-101](https://www.vision.ee.ethz.ch/datasets_extra/food-101/) | [Bossard, Lukas et al., 2014](https://pdfs.semanticscholar.org/8e3f/12804882b60ad5f59aad92755c5edb34860e.pdf) | [download](https://s3.amazonaws.com/fast-ai-imageclas/food-101.tgz) | 101 food categories, with 101,000 images; 250 test images and 750 training images per class. The training images were not cleaned. All images were rescaled to have a maximum side length of 512 pixels.
[Stanford cars](https://ai.stanford.edu/~jkrause/cars/car_dataset.html) | [Jonathan Krause et al., 2013](https://ai.stanford.edu/~jkrause/papers/3drr13.pdf) | [download](https://s3.amazonaws.com/fast-ai-imageclas/stanford-cars.tgz) | 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year.
[Imagenette](https://github.com/fastai/imagenette) | Based on [Deng et al., 2009](http://www.image-net.org/papers/imagenet_cvpr09.bib) | [Full size](https://s3.amazonaws.com/fast-ai-imageclas/imagenette.tgz) [320 px](https://s3.amazonaws.com/fast-ai-imageclas/imagenette-320.tgz) [160 px](https://s3.amazonaws.com/fast-ai-imageclas/imagenette-160.tgz) | A subset of 10 easily classified classes from Imagenet: tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute
[Imagewoof](https://github.com/fastai/imagenette) | Based on [Deng et al., 2009](http://www.image-net.org/papers/imagenet_cvpr09.bib) | [Full size](https://s3.amazonaws.com/fast-ai-imageclas/imagewoof.tgz) [320 px](https://s3.amazonaws.com/fast-ai-imageclas/imagewoof-320.tgz) [160 px](https://s3.amazonaws.com/fast-ai-imageclas/imagewoof-160.tgz) | A subset of 10 harder to classify classes from Imagenet (all dog breeds): Australian terrier, Border terrier, Samoyed, beagle, Shih-Tzu, English foxhound, Rhodesian ridgeback, dingo, golden retriever, Old English sheepdog

## Image localization

Source | Citation | Download | Description
--- | --- | --- | ---
[Camvid: Motion-based Segmentation and Recognition Dataset](http://mi.eng.cam.ac.uk/research/projects/VideoRec/CamVid/) | [Brostow et al., 2008](https://pdfs.semanticscholar.org/08f6/24f7ee5c3b05b1b604357fb1532241e208db.pdf) | [download](https://s3.amazonaws.com/fast-ai-imagelocal/camvid.tgz) | Segmentation dataset with per-pixel semantic segmentation of over 700 images, each inspected and confirmed by a second person for accuracy.
[PASCAL Visual Object Classes (VOC)](http://host.robots.ox.ac.uk/pascal/VOC/) | [Everingham, M et al., 2010](http://host.robots.ox.ac.uk/pascal/VOC/pubs/everingham10.pdf) | [download](https://s3.amazonaws.com/fast-ai-imagelocal/pascal-voc.tgz) | Standardised image data sets for object class recognition - both 2007 and 2012 versions are provided here. The 2012 version has 20 classes. The train/val data has 11,530 images containing 27,450 ROI annotated objects and 6,929 segmentations. There are also simplifed version for the annotated objects of the [2007 version](https://s3.amazonaws.com/fast-ai-imagelocal/pascal_2007.tgz) and the [2012 version](https://s3.amazonaws.com/fast-ai-imagelocal/pascal_2012.tgz).

### COCO

Probably the most widely used dataset today for object localization is [COCO: Common Objects in Context](https://arxiv.org/abs/1405.0312). Provided here are all the files from the 2017 version, along with an additional *subset* dataset created by fast.ai. Details of each COCO dataset is available from the [COCO dataset page](http://cocodataset.org/#download). The fast.ai subset contains all images that contain one of five selected categories, restricting objects to just those five categories; the categories are: chair couch tv remote book vase.

- [fast.ai subset](https://s3.amazonaws.com/fast-ai-coco/coco_sample.tgz)
- [Train images](https://s3.amazonaws.com/fast-ai-coco/train2017.zip)
- [Val images](https://s3.amazonaws.com/fast-ai-coco/val2017.zip)
- [Test images](https://s3.amazonaws.com/fast-ai-coco/test2017.zip)
- [Unlabeled images](https://s3.amazonaws.com/fast-ai-coco/unlabeled2017.zip)
- [Testing Image info](https://s3.amazonaws.com/fast-ai-coco/image_info_test2017.zip)
- [Unlabeled Image info](https://s3.amazonaws.com/fast-ai-coco/image_info_unlabeled2017.zip)
- [Train/Val annotations](https://s3.amazonaws.com/fast-ai-coco/annotations_trainval2017.zip)
- [Stuff Train/Val annotations](https://s3.amazonaws.com/fast-ai-coco/stuff_annotations_trainval2017.zip)
- [Panoptic Train/Val annotations](https://s3.amazonaws.com/fast-ai-coco/panoptic_annotations_trainval2017.zip)
